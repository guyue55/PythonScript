# 学习教程（LangChain 项目）

本教程帮助你系统学习项目的目标、结构、依赖、设计与核心流程，基于当前代码准确说明，避免混淆。

## 项目介绍

- 目标：基于 LangChain 官方生态组件，构建一个标准的 RAG（检索增强生成）流水线：加载→切分→嵌入→向量索引→检索→生成。
- 特点：充分利用 LangChain 的抽象与社区集成，易扩展替换组件。

## 目录结构（当前实际）

```
LangChain项目/
├── README.md
├── requirements.txt
├── .env.example
├── app/
│   ├── __init__.py
│   ├── config.py
│   ├── loaders/
│   │   └── file_loader.py
│   ├── utils/
│   │   └── logging.py
│   ├── vectorstores/
│   │   └── store.py
│   ├── llm/
│   │   └── openai_llm.py
│   └── pipelines/
│       ├── ingest.py
│       └── qa.py
├── data/
│   ├── raw/
│   └── index/
└── scripts/
    ├── ingest.py
    └── query.py
```

## 依赖与工具（用途准确）

- `langchain` / `langchain-core`：核心抽象（Document、Embeddings、VectorStore、Prompt、Chain）。
- `langchain-community`：社区向量库与集成（FAISS、Chroma 等）。
- `langchain-openai`：OpenAI 的 LangChain 接入（`ChatOpenAI`、`OpenAIEmbeddings`）。
- `tiktoken`：分词与 token 计数（LangChain 内部依赖）。
- `python-dotenv`：加载 `.env` 配置。
- `numpy`：基础数值计算（某些链路可能用到）。
- `pydantic`：数据模型与校验（LangChain 使用）。
- `pypdf`：PDF 文档解析（用于 `loaders/file_loader.py`）。
- `faiss-cpu` / `chromadb`：向量库后端（两者任选其一）。
- `sentence-transformers`：本地嵌入模型（不使用 OpenAI 嵌入时）。

## 设计与架构

- 配置层（`app/config.py`）：统一管理路径、切分参数、模型与向量库选择。
- 加载器（`app/loaders/file_loader.py`）：读取 `.txt`/`.md`/`.pdf` 为 `Document`，携带 `source` 元数据。
- 向量库（`app/vectorstores/store.py`）：封装 FAISS/Chroma 的构建与加载，统一返回 `retriever`。
- LLM 封装（`app/llm/openai_llm.py`）：初始化 `ChatOpenAI`（需要 API Key）。
- 管道层：
  - `app/pipelines/ingest.py`：`RecursiveCharacterTextSplitter` 切分；`OpenAIEmbeddings` 或 `HuggingFaceEmbeddings`；保存索引。
  - `app/pipelines/qa.py`：使用 `create_stuff_documents_chain` + `create_retrieval_chain` 组合检索增强生成链。
- 脚本层（`scripts/`）：命令行入库与查询。

## 流程详解

- 入库（索引构建）：
  1. 文件加载为 `Document`（含 `metadata.source`）。
  2. 使用 `RecursiveCharacterTextSplitter` 切分为块。
  3. 使用配置的嵌入模型生成向量。
  4. 使用所选向量库（FAISS/Chroma）保存索引到磁盘。
- 检索 + 生成：
  1. 加载检索器（从索引目录）。
  2. 构建 Prompt：系统消息 + 人类消息（包含上下文插槽）。
  3. 使用 `create_retrieval_chain` 将检索器与合并链串起来，`invoke` 得到 `answer`。

## 代码导读（按文件）

- `app/config.py`：`AppConfig` 与 `load_config`；默认值与环境变量覆盖。
- `app/loaders/file_loader.py`：准确解析 `.txt`/`.md`/`.pdf` 为 `Document`。
- `app/vectorstores/store.py`：`build_index` 与 `load_retriever` 的统一封装；FAISS/Chroma。
- `app/llm/openai_llm.py`：对 `ChatOpenAI` 初始化与参数管控。
- `app/pipelines/ingest.py`：端到端入库管道。
- `app/pipelines/qa.py`：标准 RAG QA 链的组合。
- `scripts/ingest.py`、`scripts/query.py`：CLI 参数解析与执行路径。

## 学习建议与实践

- 对比使用 `HuggingFaceEmbeddings` 与 `OpenAIEmbeddings` 的实际效果与性能差异。
- 比较 FAISS 与 Chroma 在索引规模、加载速度和检索表现上的差异。
- 调整 Prompt 的系统指令与消息模板，观察回答稳定性、引用准确性变化。

## 常见问题与排查

- `faiss-cpu` 安装困难：改用 `VECTORSTORE=chroma`；或先使用小规模数据 + FAISS 的预构建轮子。
- OpenAI 未配置：使用 `--no_llm` 仅检索模式，或改用本地嵌入确保索引构建。
- 切分粒度不合适：调节 `CHUNK_SIZE` 与 `CHUNK_OVERLAP`；按文档结构（标题/段落）进行更细化切分（可扩展）。

---

如需在浏览器中使用，可扩展 FastAPI 接口并在 `scripts/` 添加服务启动脚本。
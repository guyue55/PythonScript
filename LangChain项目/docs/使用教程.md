# 使用教程（LangChain 项目）

提供从安装到运行的完整步骤，准确对应当前项目结构与依赖。

## 先决条件

- Python 3.9+（建议 3.10/3.11）
- 若使用 OpenAI，需要有效的 API Key

## 安装依赖

在项目根目录执行：

```
pip install -r LangChain项目/requirements.txt
```

## 配置环境变量

- 复制 `LangChain项目/.env.example` 为 `LangChain项目/.env`
- 重要字段：
  - `RAW_DATA_DIR` / `INDEX_DATA_DIR`：数据与索引路径
  - `CHUNK_SIZE` / `CHUNK_OVERLAP`：切分参数
  - `EMBEDDINGS_PROVIDER` / `EMBEDDINGS_MODEL`：嵌入模型选择（`huggingface` 或 `openai`）
  - `VECTORSTORE`：`faiss` 或 `chroma`
  - `LLM_PROVIDER` / `LLM_MODEL` / `OPENAI_API_KEY`：生成模型配置（如需生成）

## 准备数据

将 `.txt` / `.md` / `.pdf` 文档放入：

```
LangChain项目/data/raw/
```

## 构建索引（入库）

```
python LangChain项目/scripts/ingest.py --source_dir LangChain项目/data/raw --index_dir LangChain项目/data/index
```

- 参数：
  - `--source_dir`：文档源目录（不填则读取 `.env` 的 `RAW_DATA_DIR`）
  - `--index_dir`：索引保存目录（不填则读取 `.env` 的 `INDEX_DATA_DIR`）

## 执行查询

- 检索 + 生成（OpenAI 已配置）：

```
python LangChain项目/scripts/query.py --query "什么是RAG？" --index_dir LangChain项目/data/index
```

- 仅检索（不调用 LLM）：

```
python LangChain项目/scripts/query.py --query "RAG的优势？" --index_dir LangChain项目/data/index --no_llm
```

- 其他参数：
  - `--top_k`：控制返回文档片段数量（默认 4），仅在 `--no_llm` 模式打印详情。

## 常见问题与排查

- `faiss-cpu` 安装问题：使用 `VECTORSTORE=chroma` 切换到 Chroma；或先用小数据量验证流程。
- 无法调用 OpenAI：使用 `--no_llm` 模式；或在 `.env` 设置 `OPENAI_API_KEY` 并选择合适的模型。
- 上下文碎片化：增大 `CHUNK_SIZE`、适度提高 `CHUNK_OVERLAP`；按结构化切分（可扩展）。

## 进阶建议

- 返回来源引用：在生成答案时附带 `metadata['source']`，提升可信度。
- Prompt 调优：结合领域知识调整系统指令与模板，约束回答风格与引用方式。
- 向量库选择：大规模数据建议 FAISS；在线增量更新建议 Chroma。

---

需要 Web API 或评测基准时，可在 `app/` 中扩展模块并在 `scripts/` 添加启动与评测脚本。